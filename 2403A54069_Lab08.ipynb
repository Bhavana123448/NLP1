{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFGU4f6RW7kkdzj1NPyr7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavana123448/NLP1/blob/main/2403A54069_Lab08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "RZVbFOBB9SAi"
      },
      "outputs": [],
      "source": [
        "doc1 = \"Natural language processing enables computers to understand human language.\"\n",
        "\n",
        "doc2 = \"Machine learning improves system performance through experience.\"\n",
        "\n",
        "doc3 = \"Deep learning uses neural networks for complex tasks.\"\n",
        "\n",
        "doc4 = \"Text preprocessing removes noise from raw data.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [doc1, doc2, doc3, doc4]\n",
        "corpus = \" \".join(documents)\n",
        "\n",
        "print(\"Total Documents:\", len(documents))\n",
        "print(corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_o8DOje-dhT",
        "outputId": "0a331491-0e52-403d-e977-7bac6af6ac42"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Documents: 4\n",
            "Natural language processing enables computers to understand human language. Machine learning improves system performance through experience. Deep learning uses neural networks for complex tasks. Text preprocessing removes noise from raw data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "metadata": {
        "id": "V_MlkUwS-fyW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s.]', '', text)\n",
        "\n",
        "    sentences = text.split('.')\n",
        "    processed = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = sentence.strip().split()\n",
        "        if len(words) > 0:\n",
        "            words = ['<s>'] + words + ['</s>']\n",
        "            processed.append(words)\n",
        "\n",
        "    return processed\n",
        "\n",
        "sentences = preprocess(corpus)\n",
        "\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp02_Oor-kzt",
        "outputId": "4e7efde1-0088-4035-9116-94ee57489d14"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<s>', 'natural', 'language', 'processing', 'enables', 'computers', 'to', 'understand', 'human', 'language', '</s>'], ['<s>', 'machine', 'learning', 'improves', 'system', 'performance', 'through', 'experience', '</s>'], ['<s>', 'deep', 'learning', 'uses', 'neural', 'networks', 'for', 'complex', 'tasks', '</s>'], ['<s>', 'text', 'preprocessing', 'removes', 'noise', 'from', 'raw', 'data', '</s>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b8159aa"
      },
      "source": [
        "### Unigram Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8643e6d7",
        "outputId": "9f6f1e5e-c651-431b-ad60-43cd3b4a6c24"
      },
      "source": [
        "print(\"Total unique words (vocab_size):\", vocab_size)\n",
        "print(\"Total words in training data: \", total_words)\n",
        "print(\"Top 10 most common unigrams:\")\n",
        "for word, count in unigram_counts.most_common(10):\n",
        "    print(f\"  {word}: {count}\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words (vocab_size): 24\n",
            "Total words in training data:  30\n",
            "Top 10 most common unigrams:\n",
            "  <s>: 3\n",
            "  </s>: 3\n",
            "  language: 2\n",
            "  learning: 2\n",
            "  natural: 1\n",
            "  processing: 1\n",
            "  enables: 1\n",
            "  computers: 1\n",
            "  to: 1\n",
            "  understand: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24958a47"
      },
      "source": [
        "### Bigram Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8a82947",
        "outputId": "adb68acf-9438-4dde-ce2f-e6436b9cee63"
      },
      "source": [
        "print(\"Sample bigram counts (e.g., for 'natural' or 'deep'):\")\n",
        "print(\"  natural:\", dict(bigram_counts['natural']))\n",
        "print(\"  deep:\", dict(bigram_counts['deep']))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample bigram counts (e.g., for 'natural' or 'deep'):\n",
            "  natural: {'language': 1}\n",
            "  deep: {'learning': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5dffb8c"
      },
      "source": [
        "### Trigram Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "835be4d1",
        "outputId": "5d62289e-603f-4e5f-ba3f-4ef13426f592"
      },
      "source": [
        "print(\"Sample trigram counts (e.g., for ('s', 'natural') or ('machine', 'learning')):\")\n",
        "print(\"  <s> natural:\", dict(trigram_counts['<s>']['natural']))\n",
        "print(\"  machine learning:\", dict(trigram_counts['machine']['learning']))\n",
        "# You can check other pairs as well, for instance:\n",
        "# print(\"  deep learning:\", dict(trigram_counts['deep']['learning']))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample trigram counts (e.g., for ('s', 'natural') or ('machine', 'learning')):\n",
            "  <s> natural: {'language': 1}\n",
            "  machine learning: {'improves': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index = int(0.8 * len(sentences))\n",
        "train_data = sentences[:split_index]\n",
        "test_data = sentences[split_index:]\n",
        "\n",
        "print(\"Train:\", train_data)\n",
        "print(\"Test:\", test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h45_mXri-msk",
        "outputId": "66e4af90-ef95-4c6a-f52d-7cb4bb226d8f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: [['<s>', 'natural', 'language', 'processing', 'enables', 'computers', 'to', 'understand', 'human', 'language', '</s>'], ['<s>', 'machine', 'learning', 'improves', 'system', 'performance', 'through', 'experience', '</s>'], ['<s>', 'deep', 'learning', 'uses', 'neural', 'networks', 'for', 'complex', 'tasks', '</s>']]\n",
            "Test: [['<s>', 'text', 'preprocessing', 'removes', 'noise', 'from', 'raw', 'data', '</s>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0422e1b6"
      },
      "source": [
        "### Next Word Prediction (Trigram Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84da7f1a",
        "outputId": "2ba2df70-e9bf-416e-daa0-b087373b27cf"
      },
      "source": [
        "def predict_next_word_trigram(w1, w2, top_n=1):\n",
        "    if w1 not in trigram_counts or w2 not in trigram_counts[w1] or not trigram_counts[w1][w2]:\n",
        "        print(f\"No trigram data for '({w1}, {w2})'. Falling back to bigram prediction for '{w2}'.\")\n",
        "        return predict_next_word_bigram(w2, top_n)\n",
        "\n",
        "    next_word_probabilities = {}\n",
        "    current_context_sum = sum(trigram_counts[w1][w2].values())\n",
        "\n",
        "    for next_word in unigram_counts.keys():\n",
        "\n",
        "        if next_word == '<s>' and (w1 != '<s>' or w2 != '<s>'):\n",
        "            continue\n",
        "        next_word_probabilities[next_word] = trigram_prob(w1, w2, next_word)\n",
        "\n",
        "    sorted_predictions = sorted(next_word_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
        "    predicted_words = [word for word, prob in sorted_predictions[:top_n]]\n",
        "\n",
        "    return predicted_words\n",
        "\n",
        "# Example Usage:\n",
        "print(\"Predicting next word after ('<s>', 'natural'):\", predict_next_word_trigram('<s>', 'natural'))\n",
        "print(\"Predicting next word after ('machine', 'learning'):\", predict_next_word_trigram('machine', 'learning'))\n",
        "print(\"Predicting next word after ('deep', 'learning'):\", predict_next_word_trigram('deep', 'learning'))\n",
        "print(\"Predicting next word after ('to', 'understand'):\", predict_next_word_trigram('to', 'understand'))\n",
        "print(\"Predicting next word after ('nonexistent', 'context'):\", predict_next_word_trigram('nonexistent', 'context'))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting next word after ('<s>', 'natural'): ['language']\n",
            "Predicting next word after ('machine', 'learning'): ['improves']\n",
            "Predicting next word after ('deep', 'learning'): ['uses']\n",
            "Predicting next word after ('to', 'understand'): ['human']\n",
            "No trigram data for '(nonexistent, context)'. Falling back to bigram prediction for 'context'.\n",
            "No bigram data for 'context'. Returning random words.\n",
            "Predicting next word after ('nonexistent', 'context'): ['networks']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c4616f8"
      },
      "source": [
        "### Next Word Prediction (Bigram Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316e01b8",
        "outputId": "3c54ae0e-a95b-4503-867a-d8de3389fb26"
      },
      "source": [
        "def predict_next_word_bigram(current_word, top_n=1):\n",
        "    if current_word not in bigram_counts or not bigram_counts[current_word]:\n",
        "        print(f\"No bigram data for '{current_word}'. Returning random words.\")\n",
        "        return random.choices(list(unigram_counts.keys()), k=top_n)\n",
        "\n",
        "    next_word_probabilities = {}\n",
        "    total_possible_next_words = sum(bigram_counts[current_word].values()) + vocab_size\n",
        "\n",
        "    for next_word in bigram_counts[current_word]:\n",
        "        next_word_probabilities[next_word] = bigram_prob(current_word, next_word)\n",
        "\n",
        "\n",
        "    for word in unigram_counts.keys():\n",
        "        if word not in next_word_probabilities and word != '<s>':\n",
        "            next_word_probabilities[word] = bigram_prob(current_word, word)\n",
        "\n",
        "    sorted_predictions = sorted(next_word_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    predicted_words = [word for word, prob in sorted_predictions[:top_n]]\n",
        "\n",
        "    return predicted_words\n",
        "\n",
        "\n",
        "# Example Usage:\n",
        "print(\"Predicting next word after 'natural':\", predict_next_word_bigram('natural'))\n",
        "print(\"Predicting next word after 'machine':\", predict_next_word_bigram('machine'))\n",
        "print(\"Predicting next word after 'language':\", predict_next_word_bigram('language'))\n",
        "print(\"Predicting next word after 'deep':\", predict_next_word_bigram('deep'))\n",
        "print(\"Predicting next word after 'nonexistent_word':\", predict_next_word_bigram('nonexistent_word'))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting next word after 'natural': ['language']\n",
            "Predicting next word after 'machine': ['learning']\n",
            "Predicting next word after 'language': ['processing']\n",
            "Predicting next word after 'deep': ['learning']\n",
            "No bigram data for 'nonexistent_word'. Returning random words.\n",
            "Predicting next word after 'nonexistent_word': ['improves']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d6a950d"
      },
      "source": [
        "### Text Generation (Bigram Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "332ff7c6",
        "outputId": "50b77053-a49a-45b8-aedd-5f6c322eb970"
      },
      "source": [
        "def generate_sentence_bigram(max_length=15, k=1):\n",
        "    sentence = ['<s>']\n",
        "    current_word = '<s>'\n",
        "\n",
        "    while current_word != '</s>' and len(sentence) < max_length:\n",
        "        next_word = predict_next_word_bigram(current_word, k=k)[0] # Get the top predicted word, passing k\n",
        "        sentence.append(next_word)\n",
        "        current_word = next_word\n",
        "\n",
        "    return \" \".join(sentence)\n",
        "\n",
        "print(\"Generated sentence (Bigram, k=1):\", generate_sentence_bigram(k=1))\n",
        "print(\"Generated sentence (Bigram, k=0.5):\", generate_sentence_bigram(k=0.5))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentence (Bigram, k=1): <s> natural language processing enables computers to understand human language processing enables computers to understand\n",
            "Generated sentence (Bigram, k=0.5): <s> natural language processing enables computers to understand human language processing enables computers to understand\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3284f3"
      },
      "source": [
        "### Text Generation (Trigram Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1ac5158",
        "outputId": "311c9c52-4c1a-4e08-d87b-cbb36a481eb0"
      },
      "source": [
        "def generate_sentence_trigram(max_length=15, k=1):\n",
        "    sentence = ['<s>', '<s>'] # Start with two start tokens for trigram context\n",
        "\n",
        "    while sentence[-1] != '</s>' and len(sentence) < max_length + 1:\n",
        "        w1 = sentence[-2]\n",
        "        w2 = sentence[-1]\n",
        "\n",
        "        next_word = predict_next_word_trigram(w1, w2, k=k)[0] # Get the top predicted word, passing k\n",
        "        sentence.append(next_word)\n",
        "\n",
        "    return \" \".join(sentence[1:])\n",
        "\n",
        "print(\"Generated sentence (Trigram, k=1):\", generate_sentence_trigram(k=1))\n",
        "print(\"Generated sentence (Trigram, k=0.5):\", generate_sentence_trigram(k=0.5))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No trigram data for '(<s>, <s>)'. Falling back to bigram prediction for '<s>'.\n",
            "Generated sentence (Trigram, k=1): <s> natural language processing enables computers to understand human language </s>\n",
            "No trigram data for '(<s>, <s>)'. Falling back to bigram prediction for '<s>'.\n",
            "Generated sentence (Trigram, k=0.5): <s> natural language processing enables computers to understand human language </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d5adda9"
      },
      "source": [
        "### Demonstrating Add-k Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59f15844",
        "outputId": "8dc0dd1d-b9a7-423b-9114-e3eb75f9c7e3"
      },
      "source": [
        "# Example for bigram probability with k=0.5\n",
        "print(\"Bigram Probability ('natural', 'language') with k=0.5:\", bigram_prob('natural', 'language', k=0.5))\n",
        "print(\"Bigram Probability ('nonexistent_word', 'random_word') with k=0.5:\", bigram_prob('nonexistent_word', 'random_word', k=0.5))\n",
        "\n",
        "# Example for trigram probability with k=2\n",
        "print(\"Trigram Probability ('<s>', 'natural', 'language') with k=2:\", trigram_prob('<s>', 'natural', 'language', k=2))\n",
        "print(\"Trigram Probability ('nonexistent', 'context', 'word') with k=2:\", trigram_prob('nonexistent', 'context', 'word', k=2))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Probability ('natural', 'language') with k=0.5: 0.11538461538461539\n",
            "Bigram Probability ('nonexistent_word', 'random_word') with k=0.5: 0.041666666666666664\n",
            "Trigram Probability ('<s>', 'natural', 'language') with k=2: 0.061224489795918366\n",
            "Trigram Probability ('nonexistent', 'context', 'word') with k=2: 0.041666666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ba7239"
      },
      "source": [
        "### Trigram Probability Function with Laplace Smoothing (Add-one smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "112c93f8",
        "outputId": "6f9a08eb-3121-4382-cf0b-8a1de7f63a5c"
      },
      "source": [
        "def trigram_prob(w1, w2, w3):\n",
        "    return (trigram_counts[w1][w2][w3] + 1) / (sum(trigram_counts[w1][w2].values()) + vocab_size)\n",
        "print(\"Example trigram_prob('<s>', 'natural', 'language'):\", trigram_prob('<s>', 'natural', 'language'))\n",
        "print(\"Example trigram_prob('nonexistent', 'context', 'word'):\", trigram_prob('nonexistent', 'context', 'word'))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example trigram_prob('<s>', 'natural', 'language'): 0.08\n",
            "Example trigram_prob('nonexistent', 'context', 'word'): 0.041666666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0daba92a"
      },
      "source": [
        "### Next Word Prediction (Trigram Model) using Laplace Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17bc9692",
        "outputId": "4d303ce3-90ff-42a8-8554-2e0ce74b74d7"
      },
      "source": [
        "def predict_next_word_trigram(w1, w2, top_n=1, k=1):\n",
        "    if w1 not in trigram_counts or w2 not in trigram_counts[w1] or not trigram_counts[w1][w2]:\n",
        "        print(f\"No trigram data for '({w1}, {w2})'. Falling back to bigram prediction for '{w2}'.\")\n",
        "        return predict_next_word_bigram(w2, top_n, k=k)\n",
        "\n",
        "    next_word_probabilities = {}\n",
        "\n",
        "    for next_word in unigram_counts.keys():\n",
        "        if next_word == '<s>' and (w1 != '<s>' or w2 != '<s>'):\n",
        "            continue\n",
        "        next_word_probabilities[next_word] = trigram_prob(w1, w2, next_word, k=k)\n",
        "\n",
        "    sorted_predictions = sorted(next_word_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
        "    predicted_words = [word for word, prob in sorted_predictions[:top_n]]\n",
        "\n",
        "    return predicted_words\n",
        "\n",
        "# Example Usage:\n",
        "print(\"Predicting next word after ('<s>', 'natural') (k=1):\", predict_next_word_trigram('<s>', 'natural', k=1))\n",
        "print(\"Predicting next word after ('machine', 'learning') (k=0.5):\", predict_next_word_trigram('machine', 'learning', k=0.5))\n",
        "print(\"Predicting next word after ('nonexistent', 'context') (k=1):\", predict_next_word_trigram('nonexistent', 'context', k=1))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting next word after ('<s>', 'natural') (k=1): ['language']\n",
            "Predicting next word after ('machine', 'learning') (k=0.5): ['improves']\n",
            "No trigram data for '(nonexistent, context)'. Falling back to bigram prediction for 'context'.\n",
            "No bigram data for 'context'. Returning random words.\n",
            "Predicting next word after ('nonexistent', 'context') (k=1): ['neural']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unigram(data):\n",
        "    counts = Counter()\n",
        "    for sentence in data:\n",
        "        counts.update(sentence)\n",
        "    return counts\n",
        "\n",
        "unigram_counts = build_unigram(train_data)\n",
        "total_words = sum(unigram_counts.values())\n",
        "vocab_size = len(unigram_counts)\n"
      ],
      "metadata": {
        "id": "XHGH3amF-qEM"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d259ba70"
      },
      "source": [
        "### Bigram Probability Function with Laplace Smoothing (Add-one smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "452ee1ee",
        "outputId": "cd4f193d-a5ea-4a82-e08b-fb7f280a8604"
      },
      "source": [
        "def bigram_prob(w1, w2):\n",
        "    return (bigram_counts[w1][w2] + 1) / (sum(bigram_counts[w1].values()) + vocab_size)\n",
        "\n",
        "print(\"Example bigram_prob('natural', 'language'):\", bigram_prob('natural', 'language'))\n",
        "print(\"Example bigram_prob('nonexistent_word', 'random_word'):\", bigram_prob('nonexistent_word', 'random_word'))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example bigram_prob('natural', 'language'): 0.08\n",
            "Example bigram_prob('nonexistent_word', 'random_word'): 0.041666666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae245d91"
      },
      "source": [
        "### Next Word Prediction (Bigram Model) using Laplace Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21119072",
        "outputId": "76484c19-34f3-4878-c9c6-df4e79c02b43"
      },
      "source": [
        "def predict_next_word_bigram(current_word, top_n=1, k=1):\n",
        "    if current_word not in bigram_counts or not bigram_counts[current_word]:\n",
        "        print(f\"No bigram data for '{current_word}'. Returning random words.\")\n",
        "        return random.choices(list(unigram_counts.keys()), k=top_n)\n",
        "\n",
        "    next_word_probabilities = {}\n",
        "\n",
        "    for next_word in unigram_counts.keys():\n",
        "        if next_word == '<s>' and current_word != '<s>':\n",
        "            continue\n",
        "        next_word_probabilities[next_word] = bigram_prob(current_word, next_word, k=k)\n",
        "\n",
        "    sorted_predictions = sorted(next_word_probabilities.items(), key=lambda item: item[1], reverse=True)\n",
        "    predicted_words = [word for word, prob in sorted_predictions[:top_n]]\n",
        "\n",
        "    return predicted_words\n",
        "\n",
        "# Example Usage:\n",
        "print(\"Predicting next word after 'natural' (k=1):\", predict_next_word_bigram('natural', k=1))\n",
        "print(\"Predicting next word after 'machine' (k=0.5):\", predict_next_word_bigram('machine', k=0.5))\n",
        "print(\"Predicting next word after 'nonexistent_word' (k=1):\", predict_next_word_bigram('nonexistent_word', k=1))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting next word after 'natural' (k=1): ['language']\n",
            "Predicting next word after 'machine' (k=0.5): ['learning']\n",
            "No bigram data for 'nonexistent_word'. Returning random words.\n",
            "Predicting next word after 'nonexistent_word' (k=1): ['natural']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bigram(data):\n",
        "    counts = defaultdict(Counter)\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)-1):\n",
        "            counts[sentence[i]][sentence[i+1]] += 1\n",
        "    return counts\n",
        "\n",
        "bigram_counts = build_bigram(train_data)\n"
      ],
      "metadata": {
        "id": "juOp0HmY-ssC"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_trigram(data):\n",
        "    counts = defaultdict(lambda: defaultdict(Counter))\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)-2):\n",
        "            counts[sentence[i]][sentence[i+1]][sentence[i+2]] += 1\n",
        "    return counts\n",
        "\n",
        "trigram_counts = build_trigram(train_data)\n"
      ],
      "metadata": {
        "id": "vNeAFHtd-1P9"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unigram_prob(word, k=1):\n",
        "    return (unigram_counts[word] + k) / (total_words + k * vocab_size)\n",
        "\n",
        "def bigram_prob(w1, w2, k=1):\n",
        "    return (bigram_counts[w1][w2] + k) / (sum(bigram_counts[w1].values()) + k * vocab_size)\n",
        "\n",
        "def trigram_prob(w1, w2, w3, k=1):\n",
        "    return (trigram_counts[w1][w2][w3] + k) / (sum(trigram_counts[w1][w2].values()) + k * vocab_size)"
      ],
      "metadata": {
        "id": "a_0KPWlx-3xU"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_probability(sentence, model):\n",
        "    prob = 1\n",
        "\n",
        "    if model == \"unigram\":\n",
        "        for w in sentence:\n",
        "            prob *= unigram_prob(w)\n",
        "\n",
        "    elif model == \"bigram\":\n",
        "        for i in range(len(sentence)-1):\n",
        "            prob *= bigram_prob(sentence[i], sentence[i+1])\n",
        "\n",
        "    elif model == \"trigram\":\n",
        "        for i in range(len(sentence)-2):\n",
        "            prob *= trigram_prob(sentence[i], sentence[i+1], sentence[i+2])\n",
        "\n",
        "    return prob\n",
        "\n",
        "# Test on test sentence\n",
        "for s in test_data:\n",
        "    print(\"Sentence:\", \" \".join(s))\n",
        "    print(\"Unigram:\", sentence_probability(s, \"unigram\"))\n",
        "    print(\"Bigram:\", sentence_probability(s, \"bigram\"))\n",
        "    print(\"Trigram:\", sentence_probability(s, \"trigram\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGV98zBC-6U1",
        "outputId": "66b67234-4bfd-4590-cdff-f3e83d07ef3b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: <s> text preprocessing removes noise from raw data </s>\n",
            "Unigram: 4.098039538740913e-15\n",
            "Bigram: 8.075279144492282e-12\n",
            "Trigram: 2.1803253690129166e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(data, model):\n",
        "    N = 0\n",
        "    log_prob = 0\n",
        "\n",
        "    for sentence in data:\n",
        "        N += len(sentence)\n",
        "\n",
        "        if model == \"unigram\":\n",
        "            for w in sentence:\n",
        "                log_prob += np.log(unigram_prob(w))\n",
        "\n",
        "        elif model == \"bigram\":\n",
        "            for i in range(len(sentence)-1):\n",
        "                log_prob += np.log(bigram_prob(sentence[i], sentence[i+1]))\n",
        "\n",
        "        elif model == \"trigram\":\n",
        "            for i in range(len(sentence)-2):\n",
        "                log_prob += np.log(trigram_prob(sentence[i], sentence[i+1], sentence[i+2]))\n",
        "\n",
        "    return np.exp(-log_prob / N)\n",
        "\n",
        "print(\"Unigram Perplexity:\", perplexity(test_data, \"unigram\"))\n",
        "print(\"Bigram Perplexity:\", perplexity(test_data, \"bigram\"))\n",
        "print(\"Trigram Perplexity:\", perplexity(test_data, \"trigram\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP-ZuwYe--RR",
        "outputId": "ed254cac-6603-478d-cf0a-5c6839255e91"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Perplexity: 39.682831291441175\n",
            "Bigram Perplexity: 17.08197377103495\n",
            "Trigram Perplexity: 11.843979102308912\n"
          ]
        }
      ]
    }
  ]
}